\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {1}One Random Variable}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:1var}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Parameter or parameter distribution?}{1}}
\newlabel{sect:set_param}{{1.1}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Belief network of a single, discrete random variable $X$ with probability mass function $P(X)$.}}{1}}
\newlabel{fig:1var}{{1.1}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces A single random variable $X$, whose probability mass function is parameterized by $\theta $, which is itself a random variate.}}{1}}
\newlabel{fig:1var1param}{{1.2}{1}}
\newlabel{eq:int}{{1.2}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces A single random variable $X$, whose probability mass function is parameterized by $\theta $, which is set to the number $\theta ^*$.}}{2}}
\newlabel{fig:1var1param1const}{{1.3}{2}}
\newlabel{eq:fact_int}{{1.3}{2}}
\newlabel{eq:delta}{{1.4}{2}}
\newlabel{eq:param}{{1.5}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces A single random variable $X$, whose probability mass function is parameterized by the \emph  {a priori} known and fixed number $\theta ^*$.}}{2}}
\newlabel{fig:1var1const}{{1.4}{2}}
\newlabel{eq:param prior}{{1.6}{2}}
\newlabel{eq:bayes}{{1.7}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces A single random variable $X$, whose probability mass function is parameterized by $\theta $, itself given by a distribution parameterized by $\alpha $ and $\beta $.}}{3}}
\newlabel{fig:1var1param2const}{{1.5}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Learning the parameter}{3}}
\newlabel{sect:learn_param}{{1.2}{3}}
\newlabel{eq:pre_fact}{{1.9}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Multiple, independent instances of a single, observable random variable $X$, whose probability mass functions are all parameterized by the same $\theta $, which is itself a random variate, but with a non-parametric distribution.}}{3}}
\newlabel{fig:1var1paramObs}{{1.6}{3}}
\newlabel{eq:pre_obs}{{1.10}{4}}
\newlabel{eq:post_obs}{{1.11}{4}}
\newlabel{eq:learn_param}{{1.12}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Predicting on new data}{4}}
\newlabel{sect:predict_new}{{1.3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}The short answer}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}The long answer}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Same as Figure\tmspace  +\thinmuskip {.1667em}1.6\hbox {} with $X^*$ representing a new, unobserved instance of $X$.}}{5}}
\newlabel{fig:1var1paramNewObs}{{1.7}{5}}
\newlabel{eq:post_pred}{{1.22}{6}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Two Random Variables}{7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Repeat after me ...}{7}}
\newlabel{sect:d-connect}{{2.1}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Parameter separation}{7}}
\newlabel{sect:param-sep}{{2.2}{7}}
\newlabel{eq:2param_from_G}{{2.1}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Two correlated random variables, $X$ and $Y$, with their probability mass functions parameterized by $\theta _\mathrm  {x}$ and $\theta _\mathrm  {y}$, which are themselves random variables, but with non-parametric distributions.}}{8}}
\newlabel{fig:2var2param}{{2.1}{8}}
\newlabel{eq:2param_lhs}{{2.5}{8}}
\newlabel{eq:2param_prod}{{2.6}{8}}
\newlabel{eq:2param_Y}{{2.8}{8}}
\newlabel{eq:2param_X}{{2.2}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Learning the parameters}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}The short answer}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}The long answer}{10}}
\newlabel{eq:2param_likelihood_Y}{{2.15}{10}}
\newlabel{eq:2param_prior_Y}{{2.16}{10}}
\@writefile{toc}{\contentsline {subsubsection}{Extending the graph}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Multiple, independent instances of two correlated random variables, $X$ and $Y$, with their probability mass functions parameterized by $\theta _\mathrm  {x}$ and $\theta _\mathrm  {y}$, which are themselves random variables, but with non-parametric distributions.}}{11}}
\newlabel{fig:2var2paramObs}{{2.2}{11}}
\newlabel{eq:2params_obs_Y}{{2.22}{11}}
\newlabel{eq:2params_obs_X}{{2.23}{11}}
\@writefile{toc}{\contentsline {subsubsection}{Posterior of $\theta _\mathrm  {x}$}{12}}
\@writefile{toc}{\contentsline {subsubsection}{Posterior(s) of $\theta _\mathrm  {y}$}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Predicting on new data}{13}}
\newlabel{eq:post_pred_X}{{2.35}{14}}
\newlabel{eq:post_pred_Y}{{2.36}{14}}
\newlabel{eq:post_pred_joint}{{2.37}{14}}
\newlabel{eq:post_pred_XY}{{2.38}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Hyperparameters}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Bayesian hypothesis test}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Two correlated random variables, $X$ and $Y$, with their probability mass functions parameterized by $\theta _\mathrm  {x}$ and $\theta _\mathrm  {y}$, which are themselves random variables defined through their respective hyperparamters $(\alpha , \beta )$ and $(\mu , \nu )$.}}{15}}
\newlabel{fig:2var2param4const}{{2.3}{15}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Good Things Come in 3's}{16}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Continuous Variables}{17}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
